---
title: "Integração com modelos de Machine Learning"
author: "Prof. Dr. Deoclecio e Dra. Maria Gabriella"
format:
  html:
    toc: true
    toc-location: left
    fig-width: 5
    fig-height: 5
knitr: 
  opts_chunk: 
    fig-align: center
---

```{r}
#| include: false

# Ajuste global para gráficos
library(knitr)
opts_knit$set(global.par = TRUE)
par(mar = c(5, 5, 1, 1))

```

# Introdução 

Neste módulo, aprenderemos a integrar dados geoespaciais com modelos de **Machine Learning** para gerar mapas preditivos (isoscapes). Como exemplo, utilizaremos o estudo de Sena-Souza et al. (2020) (https://doi.org/10.1002/ecs2.3223 ), que mapeou a variação do **δ¹⁵N em solos da América do Sul**, combinando dados climáticos, topográficos e de uso da terra.

O objetivo do estudo foi mostrar que métodos baseados em **aprendizado de máquina, como Random Forest**, podem ser mais eficientes que técnicas geoestatísticas tradicionais (krigagem) para prever padrões espaciais de isótopos, principalmente em cenários com forte influência de variáveis ambientais.

Durante o exercício, você irá:

- Preparar dados de amostras combinados com covariáveis ambientais;
- Ajustar modelos de machine learning, por exemplo, o modelo **Random Forest**;
- Avaliar a importância das variáveis no modelo;
- Gerar um **mapa preditivo espacial** do δ¹⁵N.

Essa abordagem será a base para aplicações futuras em rastreabilidade agrícola, ambiental e modelagem de isótopos em diferentes contextos.

---


# 1. Configuração inicial

```{r}
# Limpar área de trabalho
rm(list = ls())      
gc(reset = TRUE)     
graphics.off()       

# Pacotes necessários
if (!require(here)) install.packages("here")
library(here)
library(utils)

# Verificar existência do arquivo packages.txt
packages_path <- here::here("packages.txt")

if (!file.exists(packages_path)) {
  stop("Arquivo 'packages.txt' não encontrado! Certifique-se de que está na raiz do projeto.")
}

packages <- readLines(packages_path)
installed <- packages %in% rownames(installed.packages())

if (any(!installed)) {
  install.packages(packages[!installed], repos = "https://cloud.r-project.org")
}

lapply(packages, library, character.only = TRUE)

```

# 2. Reprodutibilidade 


```{r}
set_reproducibility <- function(seed = 1350) {
  set.seed(seed)
  RNGkind(kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rounding")
}

# Set reproducibility
set_reproducibility()
```

# 3. Carregando o conjunto de dados 

Nessa etapa, o conjunto de dados gerados no módulo II será utilizado como covariáveis 
para predizer o δ¹⁵N da América do Sul.

```{r}

dn15_var_clim <- read_excel("dados/dn15_var_clim.xlsx", sheet = 1) 

head(dn15_var_clim) #leitura das primeiras 6 linhas
str(dn15_var_clim) #Estrutura dos dados

```


# 4. Preparação dos dados

Vamos definir a variável resposta e covariáveis.

```{r}
#Retirando coordenadas
dn15_var_clim <- dn15_var_clim %>% dplyr::select(-x, -y)

#Definindo a variável resposta e covariáveis 
resposta <- dn15_var_clim$d15n.obs

#Preditoras
preditoras <- dn15_var_clim %>% dplyr::select(-d15n.obs)

#Checando valores ausentes
if (anyNA(preditoras)) {
  cat("Warning: Missing values found in predictors. Please handle them before proceeding.\n")
  print(which(is.na(predictors), arr.ind = TRUE))
} else {
  cat("No missing values found in predictors.\n")
}


```



# 2 Ajuste dos modelos

## Modelo Random Forest

Os algoritmos de aprendizado de máquina (machine learning - ML) tornaram-se muito
populares para modelar grandes conjuntos de dados em que a forma da relação entre
os preditores (também conhecidos como características) e as variáveis de resposta
não é conhecida. Trabalharemos com a Random Forest, que faz parte de uma família 
de métodos chamada Árvores de Classificação e Regressão (CART). Os métodos CART 
envolvem a construção de uma árvore de decisão, em que cada ponto de ramificação 
na árvore representa uma decisão booleana (sim/não) com base no valor de uma 
característica. O fim de cada ramificação na árvore representa uma previsão 
diferente da variável de resposta.

Além dessa estrutura básica, o Random Forest (RF) emprega vários métodos que o 
tornam um método robusto e amplamente útil. Entre eles está o uso do *bagging*,
que envolve repetir o processo de ajuste da árvore várias vezes usando subconjuntos 
aleatórios dos dados de treinamento para desenvolver um conjunto de muitas árvores 
(a “floresta”). Além disso, a RF também aplica um procedimento de bagging a cada 
nó de decisão em uma árvore — em vez de escolher a decisão mais informativa entre 
todas as características do modelo, um subconjunto aleatório de características 
é escolhido e avaliado para selecionar a regra de decisão para cada nó em cada
árvore. No modelo ajustado, as decisões são tomadas com base na coleção de todas
as árvores. Isso é útil para a análise de incertezas e também torna a Random 
Forest menos suscetível ao sobreajuste do que alguns outros métodos de ML.


```{r rf1}

pred.names<- names(preditoras)

formula_rf1 <- as.formula(paste("d15n.obs ~", paste(pred.names, collapse = " + ")))

rf.mod1  <- randomForest(
  formula_rf1,
  data = dn15_var_clim,
  ntree = 2000,
  importance = TRUE,
  keep.forest = TRUE
)

rf.mod1

```

Os resultados do modelo RF com todas as variáveis sugere que mais de 62% da
variância é explicada.

Vamos dar uma olhada rápida no ajuste do modelo:


```{r plotRF}

# Criar um data frame com Observado e Predito
dados_plot <- data.frame(
  Observado = dn15_var_clim$d15n.obs,
  Predito = rf.mod1$predicted
)

# Plotar com ggplot2
ggplot(dados_plot, aes(x = Observado, y = Predito)) +
  geom_point(shape = 21, fill = "white", size = 3, color = "black") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1) +
  labs(
    x = expression("Mensurado "*delta^{15}*"N"["solo"]),
    y = expression("Predito "*delta^{15}*"N"["solo"])
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12))

```


## Seleção inicial de variáveis

Até agora, ignoramos amplamente a seleção de variáveis. Durante o desenvolvimento 
do modelo RF faz sentido permitir que o modelo explore o máximo possível de 
características do conjunto de dados, para que possa descobrir as relações preditivas 
mais úteis. Porém ao mesmo tempo, o uso de conjuntos de características excessivos 
ou muito redundantes pode tornar o ajuste do modelo mais desafiador. Assim, é ideal 
utilizar alguma abordagem de pré-seleção de variáveis. Diante disso, optamos por
utilizar o algoritmo VSURF.


```{r vsurf}

# Convertendo as variáveis preditoras para o formato matricial (requirido pelo VSURF)
preditoras_matrix <- as.matrix(preditoras)

# Rodando VSURF para seleção de variáveis
# Set reproducibility
set_reproducibility()

vsurf_result <- VSURF::VSURF(preditoras_matrix, resposta, 
                             ntree = 2000,
                             nfor.thres = 200,
                             nfor.interp = 200,
                             nfor.pred = 200,
                             nsd = 1,
                             parallel = FALSE,
                             verbose=FALSE)


#Extração das variáveis selecionadas VSURF 
threshold_vars <- names(preditoras)[vsurf_result$varselect.thres]
interp_vars    <- names(preditoras)[vsurf_result$varselect.interp]
pred_vars      <- names(preditoras)[vsurf_result$varselect.pred]

#Print das variáveis
cat("\nVariaveis selecionadas (Threshold):\n")
print(threshold_vars)

cat("nVariaveis selecionadas (Interpretação):\n")
print(interp_vars)

cat("nVariaveis selecionadas (Predição):\n")
print(pred_vars)


```

---


```{r rfVSURF}

#Construindo a formula
formula_rf2 <- as.formula(paste("d15n.obs ~", paste(pred_vars, collapse = " + ")))

set_reproducibility()

rf.mod2 <- randomForest(
  formula_rf2,
  data = dn15_var_clim,
  ntree = 2000,
  importance = TRUE,
  keep.forest = TRUE
)

rf.mod2

#Plot error OOB  vs número de árvores
plot(rf.mod2, main = "OOB Error vs Number of Trees")

```

## Tuning

O desenvolvimento de modelos de ML e IA geralmente envolve a tomada de decisões
sobre os detalhes da estrutura do modelo e/ou os procedimentos usados para
ajustá-lo. Essas decisões são refletidas como *hiperparâmetros* do modelo, que 
determinam os detalhes do modelo. Idealmente, gostaríamos de escolher os valores
dos hiperparâmetros de maneira informada para otimizar o modelo resultante. 
Já vimos um exemplo acima, em que escolhemos o número de árvores em nossa 
floresta com base na relação entre o tamanho da floresta e o erro.

Como um método de ML bastante simples, há realmente apenas mais um hiperparâmetro 
que merece consideração na regressão RF. Ele é chamado de `mtry`. 
Lembre-se de que um componente essencial do modelo RF é que cada nó de cada árvore
é selecionado com base em um subconjunto aleatório de características possíveis. 
O hiperparâmetro `mtry` determina quantas características diferentes são
consideradas na seleção da regra de decisão em cada nó.

O pacote `caret` inclui ferramentas que oferecem suporte a fluxos de trabalho 
completos para o desenvolvimento do modelo CART, incluindo funções que podem 
ser usadas para realizar a maior parte do trabalho que fizemos acima, e vale a
pena explorá-lo se você estiver começando a usar esses métodos de ML. Usaremos 
sua função `train()` para testar diferentes valores de `mtry` e encontrar o valor
que otimiza o desempenho preditivo. 


```{r tune}

rf.tune <- caret::train(formula_rf2,
                        data = dn15_var_clim,
                        ntree = 500)
rf.tune$results
rf.tune$bestTune

```


Aqui você pode ver que as diferenças entre os modelos são pequenas, mas os
melhores resultados são obtidos usando o menor valor de `mtry` (2). Esse é 
o valor que teria sido escolhido por padrão pela função `randomForest()`, 
portanto, aceitar o valor padrão para esse hiperparâmetro é adequado neste caso.


## Teste


Como os modelos de ML são altamente dependentes dos dados usados para ajustá-los
e propensos ao sobreajuste, é importante testar seu poder preditivo usando dados
que não foram usados para o treinamento do modelo. Os modelos RF têm uma característica
inerente que suporta estimativas eficientes do desempenho preditivo. Lembre-se de
que cada árvore de decisão é desenvolvida usando um subconjunto aleatório dos dados.
Isso significa que, para cada uma das árvores, há um conjunto de dados 
*out of bag* (OOB) que não foram usados no ajuste e podem ser usados para avaliar
o desempenho preditivo dessa árvore. As estatísticas de ajuste e erro que consideramos 
acima são baseadas em dados OOB — as previsões para cada ponto de dados são feitas 
usando apenas as árvores em que essa amostra não foi usada para ajustar a árvore, 
e essas previsões são comparadas com os valores observados.


Como nem todos os métodos de ML (ou outras abordagens de modelagem) permitem a
estimativa de erro OOB, muitas vezes é útil avaliar o desempenho do nosso modelo 
usando um teste de divisão de dados mais tradicional, no qual primeiro dividimos
os dados em conjuntos de teste e treinamento antes do ajuste do modelo. Um teste
simples de divisão de dados é fácil de realizar.


```{r splitData}

# Set reproducibility
set_reproducibility()
partition <- caret::createDataPartition(dn15_var_clim$d15n.obs, p = 0.8, list = FALSE)
treino <- dn15_var_clim[partition, ]
teste <- dn15_var_clim[-partition, ]

# AJustando o modelo com dados de treino
rf.train <-  randomForest(formula_rf2, data = treino, ntree = 500)

# Data frame Observado x Predito
dados_plot2 <- data.frame(
  Observado = teste$d15n.obs,
  Predito = predict(rf.train, teste)
)

# Calcular MSE
MSE_value <- mean((dados_plot2$Predito - dados_plot2$Observado)^2)
MSE_value

# Calcular R2
R2_value<- (cor(dados_plot2$Observado, dados_plot2$Predito))^2
R2_value

# ggplot com anotação
ggplot(dados_plot2, aes(x = Observado, y = Predito)) +
  geom_point(shape = 21, fill = "white", size = 3, color = "black") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1.2) +
  labs(
    x = expression("Mensurado "*delta^{15}*"N"["Solo"]),
    y = expression("Predito "*delta^{15}*"N"["Solo"])
  ) +
  annotate("text",
           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),
           y = min(dados_plot$Predito) + 0.05 * diff(range(dados_plot$Predito)),
           label = paste0("MSE = ", round(MSE_value, 2)),
           hjust = 1, vjust = 0, size = 5) +
  annotate("text",
           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),
           y = min(dados_plot$Predito) + 0.2 * diff(range(dados_plot$Predito)),
           label = paste0("R2 = ", round(R2_value, 2)),
           hjust = 1, vjust = 0, size = 5) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```


O resultado com o cojunto de teste não é muito diferente da estimativa OOB
mostrada acima. Mas isso se baseia apenas em uma divisão (aleatória) dos dados
em partes de teste e treinamento. Para aprimorar isso, pode-se repetir o processo 
acima várias vezes. Não seria difícil codificar isso sozinho, mas acontece que 
o `caret` está bem configurado para executar esse tipo de análise para você. 
O código abaixo é uma ligeira modificação do que usamos acima e usa o
objeto `fitControl` para direcionar a função `train()` para realizar o que 
chamamos de validação cruzada. Para isso, optamos por utilizar o método 
Leave-Group-Out CV (também conhecido como Monte Carlo CV).


```{r CV}

# Leave-Group-Out CV (também conhecido como Monte Carlo CV).
fitControl <- caret::trainControl(method = "LGOCV", number = 10, p = 0.8)

# Set reproducibility
set_reproducibility()
rf.mod3 <-caret::train(formula_rf2,
                  data= dn15_var_clim, method="rf",
                  trControl=fitControl)


rf.mod3$resample
rf.mod3



```


Obtemos um conjunto de métricas ligeiramente diferente aqui, mas elas são muito semelhantes às obtidas em nosso teste de dados com divisão única e na estimativa de erro OOB. A otimização e o teste de modelos de ML são um tema vasto. Para obter mais informações e exemplos de diferentes abordagens que podem ser aplicadas na modelagem CART, há um excelente texto online que acompanha o [pacote caret](https://topepo.github.io/caret/index.html).



## Compreendendo o modelo

Entender os modelos de ML (também chamados de *ML interpretável*) também é um tema vasto e em constante desenvolvimento, mas existem algumas ferramentas simples que podem nos ajudar a começar a entender como nosso modelo está se comportando. Vamos revisar brevemente duas delas.

A primeira é o gráfico de importância das variáveis, que mostra basicamente o que seu nome sugere.



```{r VIP}
varImpPlot(rf.mod3$finalModel,main='Variable Importance Plot: Base Model')

imp<-varImp(rf.mod3$finalModel)
imp$varnames <- rownames(imp) # row names to column
rownames(imp) <- NULL  

imp


varimport<-ggplot(imp, aes(x=reorder(varnames, Overall), y=Overall)) + 
  geom_point() +
  geom_segment(aes(x=varnames,xend=varnames,y=0,yend=Overall)) +
  ylab("%IncMSE") +
  xlab("Variable Name") +
  coord_flip()+
  theme_bw()+
  theme(panel.grid = element_blank(),axis.title = element_text(size = 14),axis.text = element_text(size = 12))

varimport

```

# Isoscape

Finalmente, utilizaremos a nossa melhor predição para construir um mapa espacial
do **δ¹⁵N em solos da América do Sul**.  Os modelos CART (e os modelos ML/AI em geral)
não oferecem uma abordagem analítica simples para estimar o erro de previsão com base 
na incerteza dos parâmetros (como fazem os modelos baseados em krigagem). Várias
soluções para RF surgiram. A que usaremos (florestas de regressão quantílica) 
aproveita as diferenças nas previsões entre as árvores para calcular uma distribuição 
de previsões. A aplicação do método exigirá que ajustemos um novo modelo de floresta 
de regressão quantílica e, em seguida, o apliquemos para prever quantis específicos 
da distribuição de previsão. Escolheremos os percentis 16 e 84, pois correspondem 
a $\pm$1 desvio padrão para uma distribuição normal.

---

```{r predEspacial}
# Listar todos os arquivos raster na pasta 'raster/' 
raster_files <- list.files(path = 'raster/', pattern = '\\.tif$', full.names = TRUE)  

# Carregar todos os rasters em uma lista 
# terra ->> para carregar cada arquivo raster
raster_list <- lapply(raster_files, terra::rast)  
raster_list

# Empilhar os rasters em um único objeto SpatRaster
# terra ->> para empilhar todos os rasters em um único objeto
r_stack <- terra::rast(raster_list)  

# Verificar os nomes dos rasters 
names(r_stack) <- basename(raster_files) %>% tools::file_path_sans_ext()  
print(names(r_stack))  
class(r_stack)



# Usando o pacote "ranger".
# Set reproducibility
set_reproducibility()
mod.qrf <- ranger::ranger(formula_rf2, data=dn15_var_clim, num.trees = 500, 
                   mtry = 2, quantreg = TRUE)
mod.qrf


#Predição
isoscape <- terra::predict(r_stack, rf.mod3, na.rm = TRUE)
isoscape$ci.16 <- terra::predict(r_stack, mod.qrf, type = "quantiles", quantiles = 0.16,
                        na.rm = TRUE)
isoscape$ci.84 <- terra::predict(r_stack, mod.qrf, type = "quantiles", quantiles = 0.84,
                        na.rm = TRUE)

isoscape$sd <- (isoscape$ci.84 - isoscape$ci.16) / 2


# Verificar e criar diretório para salvar os rasters, se não existir
if (!dir.exists("isoscape")) {
  dir.create("isoscape")
}

#Exportando raster
terra::writeRaster(isoscape, filename = 'isoscape/isoscape_dn15_ML.tif', overwrite = TRUE)

```

---



```{r plotIsoscape}
#| layout-ncol: 2
# Visualizar a isoscape
terra::plot(isoscape[[1]], main = "δ¹⁵N em solos da América do Sul")
terra::plot(isoscape$sd, main = "SD")

```



